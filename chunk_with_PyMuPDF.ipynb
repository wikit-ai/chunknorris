{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "from typing import Dict, List, Tuple\n",
    "import unicodedata\n",
    "import fitz\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WikitPDFParser:\n",
    "    def __init__(\n",
    "            self,\n",
    "            filepath:str,\n",
    "            chunking_method:str=\"auto\",\n",
    "            sort_by_reading_order:bool=False,\n",
    "            top_bot_margin:float=.08,\n",
    "            left_right_margin:float=.0,\n",
    "            ):\n",
    "        \"\"\"A class used to parse pdf file intelligently\n",
    "\n",
    "        Args:\n",
    "            filepath (str): path to the file (must be pdf)\n",
    "            sort_by_reading_order (bool, optional): if True, forces the sorting of all detected text boxes \n",
    "                from top to bottom and left to right. But may destroy structure of tables of graphics.\n",
    "                Only use if the text order seems off. Defaults to False.\n",
    "            top_bot_margin (float, optional): the top and bottom margins to remove, used to \n",
    "                remove headers and footers, as a float of page height percentage. Defaults to .08.\n",
    "            left_right_margin (float, optional): the left and right margins to remove, as a percentage\n",
    "                of page width. Defaults to .0.\n",
    "        \"\"\"\n",
    "        if not filepath.endswith(\".pdf\"):\n",
    "            raise ValueError(\"The provided file must be a PDF.\")\n",
    "        self.document = fitz.open(filepath)\n",
    "\n",
    "        self.chunking_method = chunking_method\n",
    "        self.doc_as_dict = self.build_doc_as_dict(sort_by_reading_order, top_bot_margin, left_right_margin)\n",
    "        self.doc_as_lines = self.consolidate_lines()\n",
    "        self.toc = self.infer_table_of_content()\n",
    "        self.chunks = self.chunk_document()\n",
    "        \n",
    "\n",
    "    def build_doc_as_dict(\n",
    "            self,\n",
    "            sort_by_reading_order:bool=False,\n",
    "            top_bot_margin:float=.08,\n",
    "            left_right_margin:float=.0\n",
    "            ) -> List[Dict]:\n",
    "\n",
    "        doc_as_dict = []\n",
    "        for page in self.document.pages():\n",
    "            scan_area = WikitPDFParser.get_page_scan_area(\n",
    "                page,\n",
    "                top_bot_margin,\n",
    "                left_right_margin\n",
    "                )\n",
    "            doc_as_dict.append(\n",
    "                page.get_text(\n",
    "                    \"dict\",\n",
    "                    sort=sort_by_reading_order,\n",
    "                    #clip=scan_area\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return doc_as_dict\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def get_page_scan_area(\n",
    "        page:fitz.Page,\n",
    "        top_bot_margin:float=.08,\n",
    "        left_right_margin:float=.0\n",
    "        ) -> fitz.Rect:\n",
    "        \"\"\"Get the area to scan from a page, by offseting the bounding \n",
    "        rectangle a the page by the specified offset. Used to remove\n",
    "        headers and footers.\n",
    "\n",
    "        Args:\n",
    "            page (fitz.Page): a page from the document\n",
    "            top_bot_margin (float, optional): the amount of page to remove on y axis. Defaults to .08.\n",
    "            left_right_margin (float, optional): the amount of page to remove on x axis. Defaults to .0\n",
    "\n",
    "        Returns:\n",
    "            fitz.Rect: the area of the page to take into account\n",
    "        \"\"\"\n",
    "        page_rectangle = page.bound()\n",
    "        return fitz.Rect([\n",
    "            int(page_rectangle[0] + left_right_margin*page_rectangle[2]),\n",
    "            int(page_rectangle[1] + top_bot_margin*page_rectangle[3]),\n",
    "            int(page_rectangle[2] - left_right_margin*page_rectangle[2]),\n",
    "            int(page_rectangle[3] - top_bot_margin*page_rectangle[3])\n",
    "            ])\n",
    "    \n",
    "\n",
    "    def infer_table_of_content(self) -> List[Dict]:\n",
    "        \"\"\"Tries to find the table of content based on regex matches        \n",
    "\n",
    "        Returns:\n",
    "            List[Dict]: The potential titles of the table of content\n",
    "                and their caracteristics\n",
    "        \"\"\"\n",
    "        # Try to find a table of content (TOC)\n",
    "        # A TOC is just a line whose text maching the regex \"text .... number\"\n",
    "        potential_toc_titles = []\n",
    "        for line in self.doc_as_lines:\n",
    "            toc_regex_match = re.match(r\"(.+?)(\\s+)?[._-]{3,}(\\s+)?(\\d+)\", line[\"text\"])\n",
    "            if toc_regex_match is not None:\n",
    "                page_number = toc_regex_match[4]\n",
    "                potential_toc_titles.append({\n",
    "                    \"title\": toc_regex_match[1],\n",
    "                    \"page_id\": int(page_number),\n",
    "                    \"fonts\": line[\"fonts\"],\n",
    "                    \"sizes\": line[\"sizes\"],\n",
    "                    \"x_offset\": round(line[\"bbox\"][0], 1)\n",
    "                    })\n",
    "\n",
    "        if len(potential_toc_titles) > 0:\n",
    "            potential_toc_titles = WikitPDFParser._infer_table_of_content_schema(potential_toc_titles)\n",
    "            print(\"Table of content found !\")\n",
    "\n",
    "        return potential_toc_titles\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _infer_table_of_content_schema(potential_toc_titles:List[Dict]) -> List[Dict]:\n",
    "        \"\"\"Guess the level of each title, taking into account the position of the title\n",
    "        We assume we go down in levels for each right tab\n",
    "\n",
    "        Args:\n",
    "            potential_toc_titles (List[Dict]): the table of content title infered from\n",
    "            infer_table_of_content()\n",
    "\n",
    "        Raises:\n",
    "            NotImplementedError: _description_\n",
    "\n",
    "        Returns:\n",
    "            List[Dict]: _description_\n",
    "        \"\"\"\n",
    "        # Get the different x_offsets\n",
    "        x_pos_levels = sorted(set([title[\"x_offset\"] for title in potential_toc_titles]))\n",
    "        # If we have various x offsets, we can infer title level using them\n",
    "        # So far, infering using regex is buggy so we only use offsets\n",
    "        if len(x_pos_levels) > 1 or True:\n",
    "            # save a mapping of xoffset -> level\n",
    "            level2offset_mapping = {x:i for i, x in enumerate(x_pos_levels)}\n",
    "            potential_toc_titles = [\n",
    "                d|{\"level\": level2offset_mapping[d[\"x_offset\"]]}\n",
    "                for d in potential_toc_titles\n",
    "                ]\n",
    "        # Else use regex to detect numerotation and infer levels\n",
    "        else:\n",
    "            potential_toc_titles = [\n",
    "                d|dict(zip([\"level\", \"numerotation\"], WikitPDFParser._infer_with_regex(d[\"title\"])))\n",
    "                for d in potential_toc_titles\n",
    "                ]\n",
    "\n",
    "        # Find the parents titles of each subtitle in multiple level TOC\n",
    "        parents_buffer = [None] * (max([d[\"level\"] for d in potential_toc_titles]) + 1)\n",
    "        for title in potential_toc_titles:\n",
    "            parents_buffer[title[\"level\"]] = title[\"title\"]\n",
    "            parents = parents_buffer[:title[\"level\"]]\n",
    "            title[\"parents\"] = [p for p in parents if p is not None]\n",
    "\n",
    "        return potential_toc_titles\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def _infer_with_regex(text:str) -> Tuple[int, str]:\n",
    "        \"\"\"Infer the level of the title based on its numerotation \n",
    "        (such as 1.1)\n",
    "\n",
    "        Args:\n",
    "            text (str): the title text\n",
    "\n",
    "        Returns:\n",
    "            (int, str): the level (of the title), and its numerotation\n",
    "        \"\"\"\n",
    "        regex = \"(^[a-zA-Z0-9])[.)\\s]?([a-zA-Z0-9])?[.)]?([a-zA-Z0-9])?[.)]?\\s+?\"\n",
    "        matches = re.match(regex, text)\n",
    "        level = matches.span()[1]-1 if matches is not None else 0\n",
    "        numerotation = matches[0] if matches is not None else None\n",
    "\n",
    "        return level, numerotation\n",
    "\n",
    "\n",
    "    def show_page_elements(self, elem_to_show:str=\"blocks\"):\n",
    "        \"\"\"Shows the coordinates of the blocks or the chunks\n",
    "        on the pdf by drawing squares\n",
    "\n",
    "        Args:\n",
    "            elem_to_show (str): \"blocks\" or \"chunks\"\n",
    "        Raises:\n",
    "            ValueError: if page_numbers is not a list\n",
    "        \"\"\"\n",
    "        match elem_to_show:\n",
    "            case \"blocks\":\n",
    "                for page_id, page_elems in enumerate(self.doc_as_dict):\n",
    "                    page = self.document.load_page(page_id)\n",
    "                    for block in page_elems[\"blocks\"]:\n",
    "                        rect = fitz.Rect(block[\"bbox\"])\n",
    "                        page.draw_rect(rect, color=(1,0,0), fill=(1,1,0), width=1, stroke_opacity=1, fill_opacity=.3)\n",
    "\n",
    "            case \"chunks\":\n",
    "                color_switch = True\n",
    "                for chunk in self.chunks:\n",
    "                    color_switch = not color_switch \n",
    "                    for page_id, box in zip(chunk[\"page_ids\"],chunk[\"bboxes\"]):\n",
    "                        page = self.document.load_page(page_id-1)\n",
    "                        rect = fitz.Rect(box)\n",
    "                        page.draw_rect(rect, color=(1,0,0),\n",
    "                                    fill=(int(color_switch),1,int(not color_switch)),\n",
    "                                    width=1, stroke_opacity=1, fill_opacity=.3)\n",
    "            case other:\n",
    "                raise ValueError(f\"elem_to_show argument must be 'blocks or 'chunks'. Got {other}\")\n",
    "        self.document.save(\"WikitPDFParser_Output.pdf\")\n",
    "        print(\"Document saved as:  WikitPDFParser_Output.pdf\")\n",
    "\n",
    "    \n",
    "    def get_font_caracs(doc_as_dict:List[Dict]) -> List[Dict]:\n",
    "        \"\"\"Get the caracteristics of fonts used in the document\n",
    "        output is of format [{'font': 'Calibri-Bold', 'size': 24.0, 'occurence': 1}, ...]\n",
    "\n",
    "        Args:\n",
    "            doc_as_dict (Dict): the document text as a dict. ouput from read_pdf_document\n",
    "\n",
    "        Returns:\n",
    "            Dict: list of dicts of font caracteristics\n",
    "        \"\"\"\n",
    "        # Get the font and fontsize of each line of text\n",
    "        font_caracs = []\n",
    "        for page in doc_as_dict:\n",
    "            for block in page[\"blocks\"]:\n",
    "                if block[\"type\"] == 0: # text\n",
    "                    for line in block[\"lines\"]:\n",
    "                        for span in line[\"spans\"]:\n",
    "                            if len(span[\"text\"].split()) > 0: # if text is not empty\n",
    "                                font_caracs.append({\"font\": span[\"font\"], \"size\": span[\"size\"]})\n",
    "        # counts the unique dicts to get occurences of each font-fontsize \n",
    "        occurences = Counter(frozenset(d.items()) for d in font_caracs)\n",
    "        # add the occurence to the dicts\n",
    "        font_caracs = [dict(k,occurence=v) for k,v in occurences.items()]\n",
    "        font_caracs = sorted(font_caracs, key=lambda x: x[\"size\"], reverse=True)\n",
    "        \n",
    "        return font_caracs\n",
    "\n",
    "\n",
    "    def map_font_to_doc_structure(font_caracs):\n",
    "\n",
    "        # We assume that the body's font size is the font size of the most used font\n",
    "        body_fontsize = max(font_caracs, key=lambda x: x[\"occurence\"])[\"size\"]\n",
    "        # the fonts of the body are the fonts which have the size = bodysize\n",
    "        body_fonts = set([d[\"font\"] for d in font_caracs if d[\"size\"] == body_fontsize])\n",
    "        # We assume title font are the ones with size > body font\n",
    "        titles_fonts = set([d[\"font\"] for d in font_caracs if d[\"size\"] > body_fontsize])\n",
    "        # also save other small fonts\n",
    "        other_fonts = set([d[\"font\"] for d in font_caracs if d[\"size\"] < body_fontsize])\n",
    "\n",
    "        return {\"body_fonts\": body_fonts, \"titles_fonts\": titles_fonts, \"other_fonts\": other_fonts}\n",
    "    \n",
    "\n",
    "    def chunk_document(self) -> List[Dict]:\n",
    "        \"\"\"Chunks the document.\n",
    "        If a TOC has been detected, it will try to do a chunk per title.\n",
    "        If not, it will consider the fontsize : every line the font size increases, we consider it is a new part\n",
    "\n",
    "        Raises:\n",
    "            ValueError: if the chunk method specified is \"titles\" but no TOC was detected\n",
    "\n",
    "        Returns:\n",
    "            List[Dict]: the chunks\n",
    "        \"\"\"\n",
    "        match self.chunking_method.lower():\n",
    "            case \"auto\":\n",
    "                # if a table of content has been found, split by title\n",
    "                if self.toc:\n",
    "                    merge_idxes = self.merge_lines_by_titles(self.doc_as_lines)\n",
    "                    # if chunking didn't work because titles were not found in text\n",
    "                    # then fallback to merging by fontsize\n",
    "                    if len(set(merge_idxes)) == 1:\n",
    "                        print(\"Table of content was found be chunking by title didn't work\")\n",
    "                        merge_idxes = WikitPDFParser.merge_lines_by_fontsize(self.doc_as_lines)\n",
    "                else:\n",
    "                    merge_idxes = WikitPDFParser.merge_lines_by_fontsize(self.doc_as_lines)\n",
    "            case \"fontsize\":\n",
    "                merge_idxes = WikitPDFParser.merge_lines_by_fontsize(self.doc_as_lines)\n",
    "            case \"titles\":\n",
    "                if self.toc:\n",
    "                    merge_idxes = self.merge_lines_by_titles(self.doc_as_lines)\n",
    "                else:\n",
    "                    raise ValueError(\"No table of content detected. Can't perform chunking using the 'titles' method.\")\n",
    "        chunks = WikitPDFParser.merge_lines_together(self.doc_as_lines, merge_idxes)\n",
    "\n",
    "        return chunks\n",
    "   \n",
    "\n",
    "    def consolidate_lines(self) -> List[Dict]:\n",
    "        \"\"\"Regroups the elements that belong to the same line by:\n",
    "        - merging texts together\n",
    "        - listing all fonts, sizes etc\n",
    "        - build the bouning box of the line\n",
    "        - cleaning lianes that are headers, or pages number\n",
    "        Returns:\n",
    "            List[Dict]: the consolidated lines\n",
    "        \"\"\"\n",
    "        doc_as_lines = []\n",
    "        for page_id, page in enumerate(self.doc_as_dict):\n",
    "            for block in page[\"blocks\"]:\n",
    "                if block[\"type\"] == 0:\n",
    "                    for line in block[\"lines\"]:\n",
    "                        text = \"\".join([s[\"text\"] for s in line[\"spans\"]])\n",
    "                        consolidated_line = {\n",
    "                            \"text\": WikitPDFParser.cleanup_text(text),\n",
    "                            \"fonts\": list(set([s[\"font\"] for s in line[\"spans\"]])),\n",
    "                            \"sizes\": list(set([s[\"size\"] for s in line[\"spans\"]])),\n",
    "                            \"bbox\": line[\"bbox\"],\n",
    "                            \"page_id\": page_id + 1\n",
    "                        }\n",
    "                        if len(consolidated_line[\"text\"].split()) > 0\\\n",
    "                        and consolidated_line[\"sizes\"][0] > 6:\n",
    "                            doc_as_lines.append(consolidated_line)\n",
    "        \n",
    "        doc_as_lines = WikitPDFParser.remove_header_and_footer(doc_as_lines, self.document.page_count)\n",
    "        doc_as_lines = WikitPDFParser.remove_page_tags(doc_as_lines)\n",
    "\n",
    "        return doc_as_lines\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_header_and_footer(lines, page_count:int):\n",
    "        \"\"\"\n",
    "        Removes elements that appear mutliple times inthe the pages\n",
    "        as they are likely to be a header or footer\n",
    "        \"\"\"\n",
    "        if page_count >= 3 :\n",
    "            # Count each occurences of the texts of each line\n",
    "            cntr = {}\n",
    "            for i, l in enumerate(lines):\n",
    "                if l[\"text\"] not in cntr:\n",
    "                    cntr[l[\"text\"]] = {\"count\":0, \"ids\":[]}\n",
    "                cntr[l[\"text\"]][\"count\"] += 1\n",
    "                cntr[l[\"text\"]][\"ids\"].append(i)\n",
    "            # if occurence is more that n_pages // 2 + 1, remove those lines\n",
    "            indexes2remove = [\n",
    "                v[\"ids\"] for v in cntr.values()\n",
    "                if v[\"count\"] >= page_count//2 + 1\n",
    "                ]\n",
    "            indexes2remove = [i for j in indexes2remove for i in j]\n",
    "            lines = [l for i, l in enumerate(lines) if i not in indexes2remove]\n",
    "        \n",
    "        return lines\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def remove_page_tags(lines:List[Dict]) -> List[Dict]:\n",
    "        \"\"\"Removes a line if it starts with 'page'\n",
    "        or if it is only a number as they are likely to be page numbers\n",
    "        Args:\n",
    "            lines (List[Dict]): _description_\n",
    "\n",
    "        Returns:\n",
    "            List[Dict]: the lines with page related stuff removed\n",
    "        \"\"\"\n",
    "        return [l for l in lines \n",
    "                if not l[\"text\"].isnumeric() \n",
    "                and not l[\"text\"].lower().startswith(\"page\")]\n",
    "\n",
    "\n",
    "    def merge_lines_by_titles(self, lines:List[Dict]) -> List[int]:\n",
    "        \"\"\"Group lines based on titles. Lines in between 2 titles\n",
    "        will be grouped\n",
    "\n",
    "        Args:\n",
    "            lines (List[Dict]): le lines, as returned by consolidate_lines()\n",
    "\n",
    "        Returns:\n",
    "            List[int]: a list of indexes telling to which group each line belongs\n",
    "        \"\"\"\n",
    "        merged_idxes = []\n",
    "        merge_id = 0\n",
    "        prev_line_was_title = False\n",
    "        # normalize text of lines and title. Used to make sure we match without being case sensitive or accent sensitive\n",
    "        normalized_line_text = [unidecode(line[\"text\"]).lower() for line in lines]\n",
    "        normalized_toc_text = [unidecode(t[\"title\"].lower()) for t in self.toc]\n",
    "        for i, line in enumerate(lines):\n",
    "            # Check if this line is a title. To be a title :\n",
    "            ## - it must contain the title text\n",
    "            ## - be on the same page as the title or the page after if the front page counts as 0\n",
    "            title_on_this_line = [\n",
    "                t for t, normt in zip(self.toc, normalized_toc_text)\\\n",
    "                if normt in normalized_line_text[i]\\\n",
    "                and line[\"page_id\"] in [t[\"page_id\"], t[\"page_id\"]+1]\n",
    "                ]\n",
    "            # If this line is a title, and if previous line wasn't a title, then increment index\n",
    "            if bool(title_on_this_line):\n",
    "                if not prev_line_was_title:\n",
    "                    merge_id += 1\n",
    "                prev_line_was_title = True\n",
    "            else:\n",
    "                prev_line_was_title = False\n",
    "            merged_idxes.append(merge_id)\n",
    "\n",
    "        return merged_idxes\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def merge_lines_by_fontsize(lines:List[Dict]) -> List[int]:\n",
    "        \"\"\"Groupe lines using the font size. We assume that if the font size\n",
    "        increases from a line to another, we must have hit a new title\n",
    "\n",
    "        Args:\n",
    "            lines (List[Dict]): the lines, as returned by the consolidate_lines()\n",
    "\n",
    "        Returns:\n",
    "            List[Dict]: a list of indexes telling to which group each line belongs\n",
    "        \"\"\"\n",
    "        # first we build a list of idxes indicating to which group each block belongs to\n",
    "        merge_idxes = []\n",
    "        merge_id = 0\n",
    "        last_size = 500 # initialize with large fontsize\n",
    "        for line in lines:\n",
    "            # if the block's fontsize is bigger than the previous block's fontsize, it is a new header\n",
    "            # except if it is the title of a figure \n",
    "            if line[\"sizes\"][0] > last_size\\\n",
    "            and not line[\"text\"].lower().startswith(\"figure\"):\n",
    "                merge_id += 1\n",
    "            # if the text is entirely in uppercase, it is likely to be a header\n",
    "            #if block[\"text\"].isupper():\n",
    "            #    merge_id += 1\n",
    "            merge_idxes.append(merge_id)\n",
    "            last_size = line[\"sizes\"][0]\n",
    "\n",
    "        return merge_idxes\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def merge_lines_together(lines:List[Dict], merge_idxs:List[int]):\n",
    "        \"\"\"Uses a list of indexes to merge each group of blocks\n",
    "        which have the same indexes\n",
    "\n",
    "        Args:\n",
    "            blocks (List[Dict]): the blocksas returned by consolidate_blocks()\n",
    "            merge_idx (List[int]): a list of indexes telling to which group belongs each block\n",
    "\n",
    "        Returns:\n",
    "            (List[Dict]): The blocks merged\n",
    "        \"\"\"\n",
    "        chunks = []\n",
    "        for i in set(merge_idxs):\n",
    "            lines_to_merge = [l for idx, l in zip(merge_idxs, lines) if idx == i]\n",
    "            text = \" \".join([b[\"text\"] for b in lines_to_merge])\n",
    "            new_chunk = {\n",
    "                \"text\": text,\n",
    "                \"word_count\": len(text.split()),\n",
    "                \"fonts\": set([f for b in lines_to_merge for f in b[\"fonts\"]]),\n",
    "                \"sizes\": set([s for b in lines_to_merge for s in b[\"sizes\"]]),\n",
    "                \"bboxes\": WikitPDFParser._get_bbox(lines_to_merge),\n",
    "                \"page_ids\": set([l[\"page_id\"] for l in lines_to_merge]),\n",
    "                }\n",
    "            chunks.append(new_chunk)\n",
    "\n",
    "        return chunks\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_bbox(lines:List[Dict]):\n",
    "        \"\"\"From a list of lines, gets the bbox that contains them all.\n",
    "        The box may be multipage\n",
    "\n",
    "        Args:\n",
    "            lines (List[List[float]]): List of lines, as returned by consolidate_lines()\n",
    "        \"\"\"\n",
    "        bboxes = []\n",
    "        page_ids = set([l[\"page_id\"] for l in lines])\n",
    "        for pid in page_ids:\n",
    "            lines_of_that_page = [l for l in lines if l[\"page_id\"] == pid]\n",
    "            bboxes_of_that_page = [l[\"bbox\"] for l in lines_of_that_page]\n",
    "\n",
    "            x1 = min([box[0] for box in bboxes_of_that_page])\n",
    "            y1 = min([box[1] for box in bboxes_of_that_page])\n",
    "            x2 = max([box[2] for box in bboxes_of_that_page])\n",
    "            y2 = max([box[3] for box in bboxes_of_that_page])\n",
    "\n",
    "            bboxes.append((x1, y1, x2, y2))\n",
    "\n",
    "        return bboxes\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def cleanup_text(text:str) -> str:\n",
    "        \"\"\"Just applies unidecode to the text and cleanup few things\n",
    "\n",
    "        Args:\n",
    "            text (str): the text to cleanup\n",
    "\n",
    "        Returns:\n",
    "            (str) : clean text\n",
    "        \"\"\"\n",
    "        # remove invalid chars\n",
    "        def is_invalid_char(char):\n",
    "            return unicodedata.category(char) == 'Co'\n",
    "        text = \"\".join([char for char in text if not is_invalid_char(char)])\n",
    "        # remove double spaces and trailing spaces\n",
    "        text = \" \".join(list(filter(None, text.split(\" \"))))\n",
    "            \n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n",
      "Table of content found !\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "#filename = \"./data/raw/Wikit_Charte Teletravail_01 08 2023.pdf\"\n",
    "#filename = \"./data/raw/1701871800.43557-Guide GDF Utilisateur.pdf\"\n",
    "#filename = \"./data/raw/1702463429.7771-Vade-mecum i-parapheur - v1.3.pdf\"\n",
    "#filename = \"./data/raw/1701963097.697041-Prise en main et installation de Microsoft Teams.pdf\"\n",
    "#filename = \"./data/raw/1702465761.691289-Organigramme_DSIN_04.01.2024.pdf\"\n",
    "#filename = \"./data/raw/1701963094.115837-Client Printer Logic (1).pdf\"\n",
    "#filename = \"./data/raw/1701926796.668725-Guide_Manager CHRONOTIME.pdf\"\n",
    "#filename = \"./data/raw/1701939792.419826-ENVIRONNEMENT COLLABORATEUR (02 11 23).pdf\"\n",
    "#filename = \"./data/raw/FAH - Affecter un avoir à une facture.pdf\"\n",
    "filename = \"./data/raw/FAH DIVERS_Catégorie tarifaire.pdf\"\n",
    "#filename = \"./data/raw/INSA_groupe_1A_2023.pdf\"\n",
    "#filename = \"./data/raw/Reglement_interieur_de_la_collectivite_en_vigueur_au_23_01_2020.pdf\"\n",
    "pdf_parser = WikitPDFParser(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'OBJECTIF :',\n",
       "  'page_id': 3,\n",
       "  'fonts': ['Calibri', 'Calibri-Bold'],\n",
       "  'sizes': [9.960000038146973, 11.039999961853027],\n",
       "  'x_offset': 56.1,\n",
       "  'level': 1,\n",
       "  'parents': []},\n",
       " {'title': 'COMMENT CREER UNE CATEGORIE TARIFAIRE ?',\n",
       "  'page_id': 3,\n",
       "  'fonts': ['Calibri', 'Calibri-Bold'],\n",
       "  'sizes': [9.960000038146973, 11.039999961853027],\n",
       "  'x_offset': 56.1,\n",
       "  'level': 1,\n",
       "  'parents': []},\n",
       " {'title': 'COMMENT AFFECTER UNE CATEGORIE TARIFAIRE SUR LES FICHES CLIENTS ?',\n",
       "  'page_id': 4,\n",
       "  'fonts': ['Calibri', 'Calibri-Bold'],\n",
       "  'sizes': [9.960000038146973, 11.039999961853027],\n",
       "  'x_offset': 56.1,\n",
       "  'level': 1,\n",
       "  'parents': []},\n",
       " {'title': '3.1 Comment affecter une catagorie tarifaire sur une fiche client ?',\n",
       "  'page_id': 4,\n",
       "  'fonts': ['Calibri'],\n",
       "  'sizes': [9.960000038146973, 11.039999961853027],\n",
       "  'x_offset': 46.0,\n",
       "  'level': 0,\n",
       "  'parents': []},\n",
       " {'title': '3.2 Comment affecter une catégorie tarifaire à une ensemble de clients ?',\n",
       "  'page_id': 5,\n",
       "  'fonts': ['Calibri'],\n",
       "  'sizes': [9.960000038146973, 11.039999961853027],\n",
       "  'x_offset': 46.0,\n",
       "  'level': 0,\n",
       "  'parents': []},\n",
       " {'title': 'COMMENT AFFECTER UNE CATEGORIE TARIFAIRE A UN ARTICLE ?',\n",
       "  'page_id': 6,\n",
       "  'fonts': ['Calibri', 'Calibri-Bold'],\n",
       "  'sizes': [9.960000038146973, 11.039999961853027],\n",
       "  'x_offset': 56.1,\n",
       "  'level': 1,\n",
       "  'parents': ['3.2 Comment affecter une catégorie tarifaire à une ensemble de clients ?']}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_parser.toc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document saved as:  WikitPDFParser_Output.pdf\n"
     ]
    }
   ],
   "source": [
    "pdf_parser.show_page_elements(\"chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Version 14.50.100. - Mise à jour : 12/10/2023 - Groupe ISAGRI Avenue des Censives - BP 50333 - 60026 BEAUVAIS Cedex - SAS au capital de 5 100 000 € - 327 733 432 RCS Beauvais Catégorie tarifaire SOMMAIRE 1. OBJECTIF : ........................................................................................................................................................................... 3 2. COMMENT CREER UNE CATEGORIE TARIFAIRE ? ................................................................................................................. 3 3. COMMENT AFFECTER UNE CATEGORIE TARIFAIRE SUR LES FICHES CLIENTS ? ..................................................................... 4 3.1 Comment affecter une catagorie tarifaire sur une fiche client ?............................................................................................. 4 3.2 Comment affecter une catégorie tarifaire à une ensemble de clients ? ................................................................................. 5 4. COMMENT AFFECTER UNE CATEGORIE TARIFAIRE A UN ARTICLE ? ..................................................................................... 6',\n",
       "  'word_count': 104,\n",
       "  'fonts': {'Calibri', 'Calibri-Bold', 'Tahoma'},\n",
       "  'sizes': {8.039999961853027,\n",
       "   9.960000038146973,\n",
       "   11.039999961853027,\n",
       "   12.960000038146973,\n",
       "   48.0},\n",
       "  'bboxes': [(111.73999786376953,\n",
       "    327.38653564453125,\n",
       "    521.8599853515625,\n",
       "    815.1299438476562),\n",
       "   (36.0, 45.59366989135742, 561.5758666992188, 170.6599578857422)],\n",
       "  'page_ids': {1, 2}},\n",
       " {'text': '1. OBJECTIF : Gérer différents prix de vente en fonction de la catégorie du client.',\n",
       "  'word_count': 15,\n",
       "  'fonts': {'ArialMT', 'Tahoma'},\n",
       "  'sizes': {9.960000038146973, 12.960000038146973},\n",
       "  'bboxes': [(36.0, 38.62799835205078, 376.62249755859375, 73.3371353149414)],\n",
       "  'page_ids': {3}},\n",
       " {'text': '2. COMMENT CREER UNE CATEGORIE TARIFAIRE ? ÉTAPE 1 : aller dans le menu Paramètres\\\\Tiers\\\\Catégories Tarifaires ÉTAPE 2 : taper le code et le libellé de la catégorie tarifaire à créer dans les colonnes « Code » et « Libellé » Par défaut, la catégorie tarifaire est en HT. Il est possible de la passer en TTC. De ce fait, les prix de cette catégorie seront exprimés en TTC. ÉTAPE 3 : cliquer sur le bouton « Fermer » ÉTAPE 4 : la fenêtre suivante apparaît. Cliquer sur le bouton « Oui » pour enregistrer la création de la ou des catégories tarifaires.',\n",
       "  'word_count': 103,\n",
       "  'fonts': {'ArialMT', 'Tahoma', 'Tahoma-Bold'},\n",
       "  'sizes': {9.960000038146973, 12.960000038146973},\n",
       "  'bboxes': [(36.0, 84.48798370361328, 565.36669921875, 748.2171630859375)],\n",
       "  'page_ids': {3}},\n",
       " {'text': '3. COMMENT AFFECTER UNE CATEGORIE TARIFAIRE SUR LES FICHES CLIENTS ? Il est possible de renseigner une catégorie tarifaire fiche par fiche ou sur un ensemble de clients sans devoir passer fiche par fiche. 3.1 Comment affecter une catégorie tarifaire sur une fiche client ? Pour renseigner une catégorie tarifaire d’un client uniquement, il faut : ÉTAPE 1 : aller dans le menu Ventes\\\\Clients\\\\Clients. ÉTAPE 2 : après avoir sélectionné votre client à modifier, cliquer sur la ligne « Informations facturation » ÉTAPE 3 : renseigner la catégorie tarifaire dans la zone « Catégorie tarifaire » ÉTAPE 4 : enregistrer les modifications 3.2 Comment affecter une catégorie tarifaire à un ensemble de clients ? Il est possible de faire une mise à groupée pour affecter une catégorie tarifaire à un ensemble de clients. ÉTAPE 1 : aller dans le menu Ventes\\\\Clients\\\\Liste / Travaux. ÉTAPE 2 : après avoir créé les filtres pour obtenir les clients à mettre à jour et avoir cliqué sur le bouton « Filtrer », faire un clic droit « Modifier clients ». ÉTAPE 3 : sur la fenêtre qui apparaît, rechercher la ligne « Catégorie tarifaire » qui se trouve dans la partie « Informations de facturation ». Renseigner la catégorie tarifaire en la sélectionnant dans la liste. À la suite de la modification, la ligne devient bleu ciel ÉTAPE 4 : cliquer sur le bouton « Ok » pour valider la mise à jour ÉTAPE 5 : une fenêtre de confirmation apparaît. Cliquer sur le bouton « Oui » pour valider la modification.',\n",
       "  'word_count': 258,\n",
       "  'fonts': {'ArialMT', 'Tahoma', 'Tahoma-Bold'},\n",
       "  'sizes': {9.960000038146973, 12.0, 12.960000038146973},\n",
       "  'bboxes': [(36.0, 174.84796142578125, 562.1925048828125, 593.8380126953125),\n",
       "   (36.0, 38.852996826171875, 562.0545654296875, 695.2971801757812),\n",
       "   (96.6240005493164,\n",
       "    68.99295043945312,\n",
       "    562.1925048828125,\n",
       "    267.26800537109375)],\n",
       "  'page_ids': {4, 5, 6}},\n",
       " {'text': '4. COMMENT AFFECTER UNE CATEGORIE TARIFAIRE A UN ARTICLE ? ÉTAPE 1 : aller dans le menu Articles\\\\Articles ÉTAPE 2 : après avoir sélectionné votre article, cliquer sur la ligne « Tarifs ». ÉTAPE 3 : cliquer sur le + dans l’onglet « Catégorie Tarifaire » pour ajouter la catégorie tarifaire. Pour ajouter une catégorie tarifaire, il faut que le tarif de base soit renseigné ainsi que la code de TVA. ÉTAPE 4 : dans la fenêtre « Nouveau tarif préférentiel », renseigner : ✓ La catégorie tarifaire dans la zone « Catégorie tarifaire » ✓ La quantité mini à appliquer sur la catégorie tarifaire dans la zone Quantité mini ✓ Le prix de vente HT de la catégorie tarifaire dans la zone « Prix de vente HT » La zone « Remise » se calcule selon le « Type de remise ». ÉTAPE 5 : cliquer sur le bouton « Créer » pour ajouter la nouvelle catégorie tarifaire dans la fiche de l’article Il est possible de créer plusieurs lignes pour la même catégorie tarifaire. Il suffira de changer la quantité mini et le prix de vente HT. Cette documentation correspond à la version 14.50.100 Entre deux versions, des mises à jour du logiciel peuvent être opérées sans modification de la documentation. Elles sont présentées dans la documentation des nouveautés de la version sur votre espace client. Pour supprimer une ligne, cliquer sur la ligne à supprimer puis cliquer sur le -. Pour modifier une ligne, cliquer sur la ligne puis cliquer sur le crayon bleu. ÉTAPE 6 : enregistrer la fiche article en cliquant sur la disquette',\n",
       "  'word_count': 269,\n",
       "  'fonts': {'ArialMT', 'Tahoma', 'Tahoma-Bold', 'Wingdings-Regular'},\n",
       "  'sizes': {9.960000038146973, 12.960000038146973, 12.984000205993652},\n",
       "  'bboxes': [(52.234344482421875,\n",
       "    39.59513473510742,\n",
       "    562.0252075195312,\n",
       "    778.2171630859375),\n",
       "   (36.0, 366.99798583984375, 444.0774841308594, 556.2780151367188),\n",
       "   (63.658348083496094,\n",
       "    38.852996826171875,\n",
       "    565.3163452148438,\n",
       "    735.857177734375)],\n",
       "  'page_ids': {6, 7, 8}}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_parser.chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table found !\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTable found !\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m tab \u001b[38;5;241m=\u001b[39m table_finder\u001b[38;5;241m.\u001b[39mtables[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m----> 8\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mtab\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\mathi\\miniconda3\\envs\\langchain\\lib\\site-packages\\fitz\\table.py:1279\u001b[0m, in \u001b[0;36mTable.to_pandas\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1277\u001b[0m     value \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1278\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(extract)):\n\u001b[1;32m-> 1279\u001b[0m         value\u001b[38;5;241m.\u001b[39mappend(\u001b[43mextract\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m   1280\u001b[0m     pd_dict[key] \u001b[38;5;241m=\u001b[39m value\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(pd_dict)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# FIND TABLES\n",
    "doc = fitz.open(filename)\n",
    "page = doc[14]\n",
    "table_finder = page.find_tables()  # detect the tables\n",
    "if len(table_finder.tables) > 0:\n",
    "    print(\"Table found !\")\n",
    "    tab = table_finder.tables[0]\n",
    "    df = tab.to_pandas()\n",
    "    df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
