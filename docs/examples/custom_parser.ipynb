{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement a custom Parser (NotebookParser)\n",
    "\n",
    "This tutorial is designed to provide you with additional tools for utilizing ``chunknorris`` in your specific applications. All components, including the Parser, Chunker, and Pipelines, can be tailored to meet your requirements. \n",
    "\n",
    "In this tutorial, we will focus on how to implement a **custom parser**.\n",
    "\n",
    "⚠️ **Important note**: Following the implementation of this tutorial, the ``JupyterNotebookParser`` has been implemented. It's a more robust implementation than what's presented here, so **if your aim is to parse jupyter notebooks, it's advisable to use the ``JupyterNotebookParser``**. \n",
    "\n",
    "## Goal\n",
    "\n",
    "In this tutorial let's consider you want to implement a **custom Notebook parser**.\n",
    "\n",
    "As we still want to leverage the ability of ``chunknorris`` to chunk efficiently, we must implement a parser that can be plugged into the ``MarkdownChunker`` through a pipeline. The ``MarkdownChunker`` takes as input a ``MarkdownDoc`` object, our parser has to output the markdown content in that format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import components\n",
    "from typing import Any\n",
    "import json\n",
    "from IPython.display import Markdown\n",
    "from chunknorris.parsers import AbstractParser # <-- our custom parser must inherit from this\n",
    "from chunknorris.parsers.markdown.components import MarkdownDoc # <-- object ot be fed in chunker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting point\n",
    "\n",
    "We start by importing the ``AbstractParser``. Every parser in chunknorris must inherit from it. This class only need you to implement two method, which will enable your parser to fit well with the ``chunknorris``' pipelines : \n",
    "\n",
    "- chunk_string(string : str) to parse a string.\n",
    "- chunk_file(filepath : str) to parse a file given a filepath.\n",
    "\n",
    "Both must return a ``MarkdownDoc`` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base of our class\n",
    "class NotebookParser(AbstractParser): # inherit from abstract parser\n",
    "    def parse_file(self, filepath: str) -> MarkdownDoc:\n",
    "        pass\n",
    "\n",
    "    def parse_string(self, string: str) -> MarkdownDoc:\n",
    "        pass # We have to fill this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add functionnality\n",
    "\n",
    "Let's add some functionnality to read and parse the file !\n",
    "\n",
    "We will implement 2 methods :\n",
    "- ``read_file()`` to read the file\n",
    "- ``parse_notebook_content()`` that parses the \"markdown\" and \"code\" cells of the notebook.\n",
    "\n",
    "Much more parsing work could be done but we will limite to this for the tutorial. Let's have a look at our ``NotebookParser`` class now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NotebookParser(AbstractParser): # inherit from abstract parser\n",
    "    def __init__(self, include_code_cells_outputs: bool = False) -> None:\n",
    "        self.include_code_cells_outputs = include_code_cells_outputs\n",
    "\n",
    "    def parse_file(self, filepath: str) -> MarkdownDoc:\n",
    "        \"\"\"chunks a notebook .ipynb file\"\"\"\n",
    "        file_content = self.read_file(filepath)\n",
    "        md_string = self.parse_notebook_content(file_content)\n",
    "        \n",
    "        return MarkdownDoc.from_string(md_string) # we don't return directly the markdown string, but build a MarkdownDoc with\n",
    "\n",
    "    def parse_string(self, string: str) -> MarkdownDoc:\n",
    "        raise NotImplementedError # We won't implement this as it is unlikely that the notebook content fill be passed as a string.\n",
    "\n",
    "    @staticmethod\n",
    "    def read_file(filepath: str) -> dict[str, Any]:\n",
    "        \"\"\"Reads a .ipynb file and returns its \n",
    "        content as a json dict.\n",
    "\n",
    "        Args:\n",
    "            filepath (str): path to the file\n",
    "\n",
    "        Returns:\n",
    "            dict[str, Any]: the json content of the ipynb file\n",
    "        \"\"\"\n",
    "        if not filepath.endswith(\".ipynb\"):\n",
    "            raise ValueError(\"Only .ipynb files can be passed to NotebookParser.\")\n",
    "        with open(filepath, \"r\", encoding=\"utf8\") as file:\n",
    "            content = json.load(file)\n",
    "\n",
    "        return content\n",
    "    \n",
    "    def parse_notebook_content(self, notebook_content: dict[str, Any]) -> str:\n",
    "        \"\"\"Parses\n",
    "\n",
    "        Args:\n",
    "            notebook_content (dict[str, Any]): the content of the notebook, as a json file.\n",
    "                It should be a dict of structure:\n",
    "                {'cells': [{\n",
    "                    'cell_type': 'markdown',\n",
    "                    'metadata': {},\n",
    "                    'source': <list of lines>\n",
    "                    }...]\n",
    "\n",
    "        Returns:\n",
    "            str: the markdown string parsed from the notebook content\n",
    "        \"\"\"\n",
    "        kernel_language = notebook_content[\"metadata\"][\"kernelspec\"][\"language\"]\\\n",
    "            if notebook_content[\"metadata\"] else \"\"\n",
    "        md_string = \"\"\n",
    "        for cell in notebook_content[\"cells\"]:\n",
    "            match cell[\"cell_type\"]:\n",
    "                case \"markdown\" | \"raw\":\n",
    "                    md_string += \"\".join(cell[\"source\"]) + \"\\n\\n\"\n",
    "                case \"code\":\n",
    "                    language = cell[\"metadata\"][\"kernelspec\"][\"language\"] if cell[\"metadata\"] else kernel_language\n",
    "                    md_string += \"```\" + language + \"\\n\" + \"\".join(cell['source']) + \"\\n```\\n\\n\"\n",
    "                    if self.include_code_cells_outputs:\n",
    "                        md_string += \"\".join(cell[\"outputs\"].get(\"data\", {}).get('text/plain', \"\")) + \"\\n\\n\"\n",
    "                case _:\n",
    "                    pass\n",
    "\n",
    "        return md_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use our parser to get chunks\n",
    "\n",
    "Now the parser is ready, **let's use it** !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_notebook = \"./custom_parser.ipynb\" # as an example we will use... this notebook !\n",
    "notebook_parser = NotebookParser(include_code_cells_outputs=False)\n",
    "md_doc = notebook_parser.parse_file(path_to_notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Implement a custom Parser (NotebookParser)\n",
       "\n",
       "This tutorial is designed to provide you with additional tools for utilizing ``chunknorris`` in your specific applications. All components, including the Parser, Chunker, and Pipelines, can be tailored to meet your requirements.\n",
       "\n",
       "In this tutorial, we will focus on how to implement a **custom parser**.\n",
       "\n",
       "⚠️ **Important note**: Following the implementation of this tutorial, the ``JupyterNotebookParser`` has been implemented. It's a more robust implementation than what's presented here, so **if your aim is to parse jupyter notebooks, it's advisable to use the ``JupyterNotebookParser``**.\n",
       "\n",
       "## Goal\n",
       "\n",
       "In this tutorial let's consider you want to implement a **custom Notebook parser**.\n",
       "\n",
       "As we still want to leverage the ability of ``chunknorris`` to chunk efficiently, we must implement a parser that can be plugged into the ``MarkdownChunker`` through a pipeline. The ``MarkdownChunker`` takes as input a ``MarkdownDoc`` object, our parser has to output the markdown content in that format.\n",
       "\n",
       "```python\n",
       "# Import components\n",
       "from typing import Any\n",
       "import json\n",
       "from IPython.display import Markdown\n",
       "from chunknorris.parsers import AbstractParser # <-- our custom parser must inherit from this\n",
       "from chunknorris.parsers.markdown.components import MarkdownDoc # <-- object ot be fed in chunker\n",
       "```\n",
       "\n",
       "## Starting point\n",
       "\n",
       "We start by importing the ``AbstractParser`` [...]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before feeding the parsed result to the chunker, **let's have a look** at the markdown it outputs.\n",
    "Markdown(md_doc.to_string()[:1400] + \" [...]\") # only print out the first 1400 caracters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________\n",
    "That parsed result looks great ! Now let's chunk it !\n",
    "\n",
    "You can directly feed the ``MarkdownDoc`` to the ``MarkdownChunker.chunk()`` method. But I would suggest to use the BasePipeline to do this as it enables extra functionnality for saving the chunks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chunknorris.chunkers import MarkdownChunker\n",
    "from chunknorris.pipelines import BasePipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-20 10:11:ChunkNorris:INFO:Function \"chunk\" took 0.0014 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 6 chunks !\n",
      "============ chunk 0 ============\n",
      "# Implement a custom Parser (NotebookParser)\n",
      "\n",
      "This tutorial is designed to provide you with additional tools for utilizing ``chunknorris`` in your specific applications. All components, including the Parser, Chunker, and Pipelines, can be tailored to meet your requirements.\n",
      "\n",
      "In this tutorial, we will focus on how to implement a **custom parser**.\n",
      "\n",
      "⚠️ **Important note**: Following the implementation of this tutorial, the ``JupyterNotebookParser`` has been implemented. It's a more robust implementation than what's presented here, so **if your aim is to parse jupyter notebooks, it's advisable to use the ``JupyterNotebookParser``**.\n",
      "============ chunk 1 ============\n",
      "# Implement a custom Parser (NotebookParser)\n",
      "\n",
      "## Goal\n",
      "\n",
      "In this tutorial let's consider you want to implement a **custom Notebook parser**.\n",
      "\n",
      "As we still want to leverage the ability of ``chunknorris`` to chunk efficiently, we must implement a parser that can be plugged into the ``MarkdownChunker`` through a pipeline. The ``MarkdownChunker`` takes as input a ``MarkdownDoc`` object, our parser has to output the markdown content in that format.\n",
      "\n",
      "```python\n",
      "# Import components\n",
      "from typing import Any\n",
      "import json\n",
      "from IPython.display import Markdown\n",
      "from chunknorris.parsers import AbstractParser # <-- our custom parser must inherit from this\n",
      "from chunknorris.parsers.markdown.components import MarkdownDoc # <-- object ot be fed in chunker\n",
      "```\n",
      "============ chunk 2 ============\n",
      "# Implement a custom Parser (NotebookParser)\n",
      "\n",
      "## Starting point\n",
      "\n",
      "We start by importing the ``AbstractParser``. Every parser in chunknorris must inherit from it. This class only need you to implement two method, which will enable your parser to fit well with the ``chunknorris``' pipelines :\n",
      "\n",
      "- chunk_string(string : str) to parse a string.\n",
      "- chunk_file(filepath : str) to parse a file given a filepath.\n",
      "\n",
      "Both must return a ``MarkdownDoc`` object.\n",
      "\n",
      "```python\n",
      "# Base of our class\n",
      "class NotebookParser(AbstractParser): # inherit from abstract parser\n",
      "def parse_file(self, filepath: str) -> MarkdownDoc:\n",
      "pass\n",
      "\n",
      "def parse_string(self, string: str) -> MarkdownDoc:\n",
      "pass # We have to fill this\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "pipe = BasePipeline(\n",
    "    parser=NotebookParser(), \n",
    "    chunker=MarkdownChunker(max_chunk_word_count=100)\n",
    "    )\n",
    "\n",
    "chunks = pipe.chunk_file(path_to_notebook)\n",
    "print(f\"Got {len(chunks)} chunks !\")\n",
    "for i, chunk in enumerate(chunks[:3]):\n",
    "    print(f\"============ chunk {i} ============\")\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________\n",
    "## Conclusion\n",
    "\n",
    "There you go ! Take note the ``chunknorris`` will always try to preserve the intergrity of code blocks.\n",
    "\n",
    "One last tip: if you wish to customize the behavior of one specific parser instead (HTMLParser for example), you might want to inherit directly from that parser instead of starting from stratch with AbstractParser."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chunknorris",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
