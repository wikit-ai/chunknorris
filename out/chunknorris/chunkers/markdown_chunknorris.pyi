from ..exceptions.exceptions import ChunkSizeExceeded as ChunkSizeExceeded
from ..types.types import Chunk as Chunk, Chunks as Chunks, TocTree as TocTree
from _typeshed import Incomplete

class MarkdownChunkNorris:
    tokenizer: Incomplete
    def __init__(self) -> None: ...
    def __call__(self, md_text: str, **kwargs) -> Chunks: ...
    def get_toc_tree(self, markdown_string: str, max_title_level_to_use: str = 'h4', header_style: str = 'setext', **kwargs) -> TocTree: ...
    @staticmethod
    def save_toc_tree(toc_tree: TocTree, output_path: str = 'toc_tree.json'): ...
    @staticmethod
    def get_title_by_id(toc_tree: TocTree, id: int) -> TocTree: ...
    def get_chunks(self, toc_tree: TocTree, **kwargs) -> Chunks: ...
    @staticmethod
    def get_chunks_texts(toc_tree_element: TocTree, already_ok_chunks: Chunks | None = None, **kwargs) -> Chunks: ...
    @staticmethod
    def build_chunk_text(toc_tree_element: TocTree) -> Chunk: ...
    @staticmethod
    def get_parents_headers(toc_tree_element: TocTree) -> list[str]: ...
    @staticmethod
    def change_links_format(text, link_placement: str = 'in_sentence', **kwargs) -> str: ...
    @staticmethod
    def remove_small_chunks(chunks: Chunks, min_chunk_word_count: int = 15, **kwargs) -> Chunks: ...
    def split_big_chunks(self, chunks: Chunks, max_chunk_tokens: int = 8191, chunk_tokens_exceeded_handling: str = 'raise_error', **kwargs) -> Chunks: ...
    def get_token_count(self, text: Chunk) -> int: ...
