{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from src.RAG_dataset_generator import RAGDatasetGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNKS_FOLDER = \"../../data\\D26\\ladrome-2023-12-22-page-chunked-v1\"\n",
    "FILE_LIST = os.listdir(CHUNKS_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "handmade_dataset = pd.read_excel(\"../../data/D26/D26_dataset_handmade.xlsx\")\n",
    "handmade_dataset[\"relevant_chunk_ids\"] = handmade_dataset[\"relevant_chunk_ids\"].str.split(\" \")\n",
    "handmade_dataset.dropna(subset=\"relevant_chunk_ids\", inplace=True)\n",
    "\n",
    "filenames = handmade_dataset[\"relevant_chunk_ids\"].tolist()\n",
    "filenames = [fn[0] for fn in filenames]\n",
    "\n",
    "dataset_generator = RAGDatasetGenerator(\"openai\", model=\"gpt-3.5-turbo\")\n",
    "dataset_generator.generate_RAG_dataset(CHUNKS_FOLDER, filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_generator = RAGDatasetGenerator(\"openai\", model=\"gpt-3.5-turbo\")\n",
    "\n",
    "questions = []\n",
    "answers = []\n",
    "short_answers = []\n",
    "relevant_ids = []\n",
    "for chunk_ids in reversed(handmade_dataset[\"relevant_chunk_ids\"].tolist()):\n",
    "    chunk_id = chunk_ids[0]\n",
    "    chunk = read_json(os.path.join(CHUNKS_FOLDER, chunk_id))\n",
    "    text = chunk[\"text\"]\n",
    "    question = dataset_generator.generate_questions_from_chunk(text, 1)[0]\n",
    "    answer = dataset_generator.generate_answer(question, text)\n",
    "    short_answer = dataset_generator.generate_answer(question, text, short=True)\n",
    "    questions.append(question)\n",
    "    answers.append(answer)\n",
    "    short_answers.append(short_answer)\n",
    "    relevant_ids.append(chunk_id)\n",
    "    break\n",
    "\n",
    "generated_df = pd.DataFrame.from_dict({\"query\": questions, \"relevant_chunk_ids\": relevant_ids, \"long_answer\": answers, \"short_answer\": short_answers})\n",
    "generated_df.to_csv(os.path.join(os.path.dirname(CHUNKS_FOLDER), \"generated_dataset.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [06:16<00:00,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved at : ../../data\\D26\\generated_data_gpt-3-5-turbo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "filenames = handmade_dataset[\"relevant_chunk_ids\"].tolist()\n",
    "filenames = [fn[0] for fn in filenames]\n",
    "\n",
    "dataset_generator = RAGDatasetGenerator(\"openai\", model=\"gpt-3.5-turbo\")\n",
    "dataset_generator.generate_RAG_dataset(CHUNKS_FOLDER, filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d26",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
