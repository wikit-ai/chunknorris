{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New chunking method based on titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src.chunkers.HTMLChunkNorris import HTMLChunkNorris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': -1, 'text': '', 'level': -1, 'start_position': -1, 'end_position': -1, 'children': [], 'parents': [], 'content': '>'}]\n",
      "\n",
      "======================================\n",
      "\n",
      ">\n",
      "\n"
     ]
    }
   ],
   "source": [
    "html_cn = HTMLChunkNorris()\n",
    "\n",
    "## LaDrome\n",
    "SOURCE_FOLDER = \"../../../data/D26/ladrome-2023-12-22-page/\"\n",
    "\n",
    "# FILE = \"ladrome-page-13830.json\"\n",
    "# FILE = \"ladrome-page-10516.json\"\n",
    "# FILE = \"ladrome-page-61504.json\"\n",
    "# FILE = \"ladrome-page-504967.json\"\n",
    "# FILE = \"ladrome-page-567239.json\"\n",
    "# FILE = \"ladrome-page-13718.json\"\n",
    "# FILE = \"ladrome-page-10516.json\"\n",
    "# FILE = \"ladrome-page-547344.json\" # big chunks\n",
    "# FILE = \"ladrome-page-574603.json\" # no title, just a list of links\n",
    "# FILE = \"ladrome-page-581681.json\" # plein de petits titres\n",
    "# FILE = \"ladrome-page-10787.json\"\n",
    "FILE = \"ladrome-page-11020.json\"\n",
    "\n",
    "# INSALyon\n",
    "SOURCE_FOLDER = \"../../data/INSALyon/insalyon-2023-12-13-page/\"\n",
    "SOURCE_FOLDER = \"../../../data/INSALyon/insalyon-2023-11-27-formations/\"\n",
    "\n",
    "\n",
    "# FILE = \"rejoindreinsalyon-page-500.json\"\n",
    "FILE = \"bachelor.json\"\n",
    "# FILE = \"rejoindreinsalyon-page-160.json\"\n",
    "# FILE = \"rejoindreinsalyon-page-4314.json\"\n",
    "# FILE = \"rejoindreinsalyon-page-3908.json\"\n",
    "\n",
    "file = HTMLChunkNorris.read_json_file(os.path.join(SOURCE_FOLDER, FILE))\n",
    "# print(file)\n",
    "titles = html_cn.get_toc(file)\n",
    "print(titles)\n",
    "#chunks = html_cn.get_chunks(titles, FILE)\n",
    "# print(chunks)\n",
    "chunks = html_cn(\n",
    "    os.path.join(SOURCE_FOLDER, FILE),\n",
    "    max_title_level_to_use=\"h3\",\n",
    "    max_chunk_word_length=200,\n",
    "    link_placement=\"in_sentence\",\n",
    "    chunk_tokens_exceeded_handling=\"split\"\n",
    "    )\n",
    "print(\"\\n======================================\\n\")\n",
    "for c in chunks:\n",
    "    print(c[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunk entire folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Output directory already contains data !",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m OUTPUT_FOLDER \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mINPUT_FOLDER\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-chunked-v1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m html_cn \u001b[38;5;241m=\u001b[39m HTMLChunkNorris()\n\u001b[1;32m----> 7\u001b[0m \u001b[43mhtml_cn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_entire_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mINPUT_FOLDER\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mOUTPUT_FOLDER\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_title_level_to_use\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mh3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_chunk_word_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m250\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlink_placement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43min_sentence\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunk_tokens_exceeded_handling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msplit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mathi\\Wikit\\Chunk_Norris\\chunk-norris\\HTMLs\\src\\chunkers\\HTMLChunkNorris.py:85\u001b[0m, in \u001b[0;36mHTMLChunkNorris.chunk_entire_directory\u001b[1;34m(self, input_dir, output_dir, min_chunk_wordcount, **kwargs)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Chunks the json files of entire directory\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \n\u001b[0;32m     79\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;124;03m    min_chunk_wordcount (int, optional): minimum words to consider saving the chunks. Defaults to 15.\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(output_dir) \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(output_dir):\n\u001b[1;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput directory already contains data !\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(output_dir):\n\u001b[0;32m     87\u001b[0m     os\u001b[38;5;241m.\u001b[39mmkdir(output_dir)\n",
      "\u001b[1;31mValueError\u001b[0m: Output directory already contains data !"
     ]
    }
   ],
   "source": [
    "from src.chunkers.HTMLChunkNorris import HTMLChunkNorris\n",
    "\n",
    "INPUT_FOLDER = \"../../../data\\INSALyon\\insalyon-2023-11-27-formations\"\n",
    "OUTPUT_FOLDER = f\"{INPUT_FOLDER}-chunked-v1\"\n",
    "\n",
    "html_cn = HTMLChunkNorris()\n",
    "html_cn.chunk_entire_directory(\n",
    "    INPUT_FOLDER,\n",
    "    OUTPUT_FOLDER,\n",
    "    max_title_level_to_use=\"h3\",\n",
    "    max_chunk_word_length=250,\n",
    "    link_placement=\"in_sentence\",\n",
    "    chunk_tokens_exceeded_handling=\"split\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d26",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
